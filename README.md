<h1 align="center">ğŸ’³ Monitoramento de TransaÃ§Ãµes Financeiras com PySpark + Airflow</h1>

<p align="center">
  <strong>Projeto de Engenharia de Dados</strong> com ingestÃ£o, processamento e enriquecimento de transaÃ§Ãµes financeiras simuladas.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/status-em%20desenvolvimento-yellow" />
  <img src="https://img.shields.io/badge/python-3.10-blue" />
  <img src="https://img.shields.io/badge/spark-4.0-orange" />
  <img src="https://img.shields.io/badge/airflow-2.7+-green" />
</p>

---

## ğŸ§­ VisÃ£o Geral

Este pipeline ETL simula transaÃ§Ãµes bancÃ¡rias e as **enriquece com dados pÃºblicos** para identificar padrÃµes e facilitar anÃ¡lises. O projeto foca em:

- ğŸ”„ OrquestraÃ§Ã£o com Airflow  
- âš¡ Processamento distribuÃ­do com PySpark  
- ğŸ”’ SeguranÃ§a com mascaramento de dados sensÃ­veis  
- ğŸ“ˆ Escalabilidade e observabilidade  
- ğŸ§± Arquitetura em camadas (Bronze, Silver, Gold)

---

## âš™ï¸ Tecnologias Utilizadas

- ğŸ **Python 3.10.12**
- ğŸ”¥ **Apache Spark 4.0**
- ğŸŒ¬ï¸ **Apache Airflow 2.7+**
- ğŸ˜ **PySpark**
- ğŸ³ **Docker** (opcional, para execuÃ§Ã£o isolada)
- ğŸ“¦ **Kaggle Datasets + IBGE (dados pÃºblicos)**
- ğŸ“Š **Streamlit**
---

## ğŸ§± Arquitetura em Camadas (Medallion Architecture)

| Camada  | DescriÃ§Ã£o |
|---------|----------|
| ğŸŸ¤ **Bronze** | Dados simulados brutos gerados com `Faker` |
| âšª **Silver** | Dados limpos, validados e enriquecidos |
| ğŸŸ¡ **Gold**   | Dados mascarados e cruzados com IBGE, Receita e Kaggle |

---

## ğŸ“ Estrutura do Projeto

```bash
.
â”œâ”€â”€ dags/                       # DAGs do Airflow
â”œâ”€â”€ data/                       # Dados particionados por camada (Bronze, Silver, Gold)
â”œâ”€â”€ scripts/                    # Scripts PySpark de transformaÃ§Ã£o
â”œâ”€â”€ dashboard/                  # Scripts Streamlit para visualizaÃ§Ã£o de dados
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o com Docker
â”œâ”€â”€ Dockerfile                  # Imagem customizada Airflow + Spark
â”œâ”€â”€ requirements.txt            # Pacotes necessÃ¡rios
â””â”€â”€ README.md                   # Este documento



## Dados Utilizados
SimulaÃ§Ã£o de TransaÃ§Ãµes (geradas com Faker)

Kaggle:

creditcard.csv

bank_marketing_full.csv

IBGE: lista de municÃ­pios e estados

Receita Federal (simulada): nomes de bancos



### COMO EXECUTAR O PROJETO 
ğŸš€ Como Executar o Projeto
1. Clonar o RepositÃ³rio

git clone https://github.com/seu-usuario/transacoes-financeiras-pipeline.git
cd transacoes-financeiras-pipeline

2. Criar Ambiente Virtual

python3 -m venv airflow-env
source airflow-env/bin/activate
pip install -r requirements.txt

3. Baixando o kaggle.json
VÃ¡ atÃ©: https://www.kaggle.com/settings

Role atÃ© a seÃ§Ã£o "API"

Clique em "Create New API Token"

Isso irÃ¡ baixar o arquivo kaggle.json com seu username e API token

/home/seu_usuario/airflow/Projeto/secrets/kaggle.json ~/.kaggle/

chmod 600 ~/.kaggle/kaggle.json

4. Subir o Airflow e Executar DAG

# Suba o docker 
Utilize o dockerfile para buildar a imagem airflow + Spark

docker-compose build

Depois utilize o comando para subir o docker

docker-compose -d

Acesse: http://localhost:8080
Login padrÃ£o: admin | Senha: admin

Ative e execute a DAG: pipeline_transacoes_pyspark



ğŸ‘¨â€ğŸ’» Autor
Leonardo Oliveira dos Santos
Engenheiro de Dados â€¢ Python | PySpark | Airflow 
LinkedIn https://www.linkedin.com/in/leonardo-oliveira-20083b1a2/  â€¢ GitHub https://github.com/Leoosantoszl?tab=repositories

